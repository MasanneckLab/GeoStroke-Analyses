{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Urban/Rural Analysis of CT Hospital Benefits\n",
        "\n",
        "This notebook demonstrates how to analyze benefit areas by their rural/urban characteristics using the GHS-SMOD (Global Human Settlement Model - Settlement Model) raster data.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The GHS-SMOD raster classifies areas by degree of urbanization using UN standards:\n",
        "- **Urban codes**: {30, 23, 22, 21} - Cities, towns, suburban areas\n",
        "- **Rural codes**: {13, 12, 11} - Rural areas with different densities\n",
        "- **Other codes**: Water bodies, very low density areas, etc.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "1. **Benefit analysis results**: Previously generated using `geostroke.benefit` functions\n",
        "2. **GHS-SMOD raster**: Download from [GHS-SMOD webpage](https://ghsl.jrc.ec.europa.eu/ghs_smod2023.php)\n",
        "   - File: `GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif` (or similar)\n",
        "   - Place in `raw_data/` directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded geostroke version 1.0.0\n",
            "üìÅ Project root: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke\n",
            "üìÅ Data directory: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data\n"
          ]
        }
      ],
      "source": [
        "# ---- 1. Install what you might still need ----\n",
        "# pip install geopandas rasterio pandas pyproj shapely\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Set working directory to project root\n",
        "import os\n",
        "os.chdir('..')  # Go\n",
        "\n",
        "import geostroke as gs\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"‚úÖ Loaded geostroke version {gs.__version__}\")\n",
        "print(f\"üìÅ Project root: {gs.config.ROOT}\")\n",
        "print(f\"üìÅ Data directory: {gs.config.DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**Update these paths for your specific files:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç File checks:\n",
            "   Benefit file exists: ‚úÖ\n",
            "   SMOD raster exists: ‚úÖ\n",
            "   Benefit file: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data/benefit_cache/benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\n",
            "   SMOD raster: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data/GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif\n"
          ]
        }
      ],
      "source": [
        "# ---- 2. Point to your inputs ----\n",
        "\n",
        "BENEFIT_FILE = gs.config.DATA_DIR / \"benefit_cache\" / \"benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\"  # <-- change to your actual file\n",
        "\n",
        "\n",
        "# GHS-SMOD raster path (adjust for your file)\n",
        "SMOD_RASTER = gs.config.DATA_DIR / \"GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif\"\n",
        "\n",
        "# Check if files exist\n",
        "print(f\"\\nüîç File checks:\")\n",
        "print(f\"   Benefit file exists: {'‚úÖ' if BENEFIT_FILE and BENEFIT_FILE.exists() else '‚ùå'}\")\n",
        "print(f\"   SMOD raster exists: {'‚úÖ' if SMOD_RASTER.exists() else '‚ùå'}\")\n",
        "\n",
        "if BENEFIT_FILE:\n",
        "    print(f\"   Benefit file: {BENEFIT_FILE}\")\n",
        "if SMOD_RASTER.exists():\n",
        "    print(f\"   SMOD raster: {SMOD_RASTER}\")\n",
        "else:\n",
        "    print(f\"   ‚ùå SMOD raster not found at: {SMOD_RASTER}\")\n",
        "    print(f\"   üì• Please download from: https://ghsl.jrc.ec.europa.eu/ghs_smod2023.php\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Generate Benefit Analysis\n",
        "\n",
        "If you don't have cached benefit results, run this cell to generate them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Benefit file exists, will load from cache\n"
          ]
        }
      ],
      "source": [
        "# ---- Alternative: Generate benefit analysis if needed ----\n",
        "\n",
        "if not BENEFIT_FILE or not BENEFIT_FILE.exists():\n",
        "    print(\"üîÑ Generating benefit analysis (this may take several minutes)...\")\n",
        "    \n",
        "    # Quick benefit analysis with coarser resolution for demo\n",
        "    benefit_gdf = gs.benefit.calculate_time_benefits_parallel(\n",
        "        ct_penalty=0.0,\n",
        "        benefit_threshold=10.0,\n",
        "        grid_resolution=0.01,  # Coarser resolution for faster processing\n",
        "        time_bins=[5,10,15,20,25, 30,35,40, 45,50,55, 60],  # Fewer time bins\n",
        "        max_workers=4\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Generated benefit analysis with {len(benefit_gdf):,} points\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚úÖ Benefit file exists, will load from cache\")\n",
        "    benefit_gdf = None  # Will be loaded in next cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Benefit Analysis Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Loading benefit analysis from: benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\n",
            "   üìã Analysis parameters: {'ct_suffix': '_all_CTs', 'stroke_suffix': '', 'time_bins': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60], 'ct_penalty': 0, 'benefit_threshold': 10.0, 'grid_resolution': 0.01, 'bounds': None}\n",
            "‚úÖ Loaded 510,229 benefit points\n",
            "\n",
            "üìä Benefit Data Summary:\n",
            "   Total points: 510,229\n",
            "   Coordinate system: EPSG:4326\n",
            "   Columns: ['geometry', 'ct_time', 'stroke_time', 'time_benefit', 'benefit_category']\n",
            "\n",
            "   Benefit categories:\n",
            "     Neither reachable within 60 min: 260,954 points\n",
            "     Low (10-20 min): 117,029 points\n",
            "     Medium (20-30 min): 72,853 points\n",
            "     High (30+ min): 37,724 points\n",
            "     Only CT reachable within 60 min: 21,106 points\n",
            "     Likely irrelevant (<10 min): 563 points\n"
          ]
        }
      ],
      "source": [
        "# ---- 3. Load the benefit GeoDataFrame ----\n",
        "\n",
        "if benefit_gdf is None:  # Not generated in previous cell\n",
        "    if BENEFIT_FILE and BENEFIT_FILE.exists():\n",
        "        print(f\"üì• Loading benefit analysis from: {BENEFIT_FILE.name}\")\n",
        "        \n",
        "        if BENEFIT_FILE.suffix == \".pkl\":\n",
        "            with BENEFIT_FILE.open(\"rb\") as f:\n",
        "                cached_data = pickle.load(f)\n",
        "            \n",
        "            # Handle both old and new cache formats\n",
        "            if isinstance(cached_data, dict) and \"data\" in cached_data:\n",
        "                # New format with metadata\n",
        "                benefit_gdf = gpd.GeoDataFrame(cached_data[\"data\"], crs=\"EPSG:4326\")\n",
        "                if \"params\" in cached_data:\n",
        "                    print(f\"   üìã Analysis parameters: {cached_data['params']}\")\n",
        "            else:\n",
        "                # Old format - direct data\n",
        "                benefit_gdf = gpd.GeoDataFrame(cached_data, crs=\"EPSG:4326\")\n",
        "        else:\n",
        "            # GeoPackage or other format\n",
        "            benefit_gdf = gpd.read_file(BENEFIT_FILE)\n",
        "            \n",
        "        print(f\"‚úÖ Loaded {len(benefit_gdf):,} benefit points\")\n",
        "        \n",
        "    else:\n",
        "        raise FileNotFoundError(\"No benefit file available. Please run benefit analysis first.\")\n",
        "\n",
        "# Display basic info about the benefit data\n",
        "print(f\"\\nüìä Benefit Data Summary:\")\n",
        "print(f\"   Total points: {len(benefit_gdf):,}\")\n",
        "print(f\"   Coordinate system: {benefit_gdf.crs}\")\n",
        "print(f\"   Columns: {list(benefit_gdf.columns)}\")\n",
        "print(f\"\\n   Benefit categories:\")\n",
        "for category, count in benefit_gdf['benefit_category'].value_counts().items():\n",
        "    print(f\"     {category}: {count:,} points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Urban/Rural Annotation\n",
        "\n",
        "Now we'll add urban/rural labels to each benefit point using the GHS-SMOD raster:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Germany grid points: 459,349\n",
            "Category counts (points):\n",
            "benefit_category\n",
            "Likely irrelevant (<10 min)        206068\n",
            "Low (10-20 min)                    116674\n",
            "Medium (20-30 min)                  72459\n",
            "High (30+ min)                      37417\n",
            "Only CT reachable within 60 min     20162\n",
            "Neither reachable within 60 min      6569\n",
            "Name: count, dtype: int64\n",
            "üèôÔ∏è Annotating grid with SMOD urban/rural classes ‚Ä¶\n",
            "‚úÖ Annotation done\n",
            "Urban/Rural distribution (all points):\n",
            "urban_rural\n",
            "rural    412,940 (89.9%)\n",
            "urban      44,554 (9.7%)\n",
            "other       1,855 (0.4%)\n",
            "Name: count, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# ---- 4. Annotate every point with rural/urban classification (FIXED to include full complement) ----\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Sanity check\n",
        "if not SMOD_RASTER.exists():\n",
        "    raise FileNotFoundError(f\"SMOD raster not found at {SMOD_RASTER}\")\n",
        "\n",
        "# Germany outline & polygon\n",
        "GERMANY = gs.data.load_germany_outline()\n",
        "GERMANY_POLY = GERMANY.geometry.iloc[0]\n",
        "\n",
        "# Infer grid resolution from the cached benefit points (fallback 0.01¬∞)\n",
        "xs_u = np.sort(benefit_gdf.geometry.x.unique())\n",
        "ys_u = np.sort(benefit_gdf.geometry.y.unique())\n",
        "try:\n",
        "    dx = np.median(np.diff(xs_u))\n",
        "    dy = np.median(np.diff(ys_u))\n",
        "    GRID_RES = round(float(min(dx, dy)), 5)\n",
        "    if GRID_RES <= 0 or GRID_RES > 0.05:\n",
        "        GRID_RES = 0.01\n",
        "except Exception:\n",
        "    GRID_RES = 0.01\n",
        "\n",
        "# Build full Germany grid\n",
        "minx, miny, maxx, maxy = GERMANY.total_bounds\n",
        "xs = np.arange(minx, maxx + GRID_RES, GRID_RES)\n",
        "ys = np.arange(miny, maxy + GRID_RES, GRID_RES)\n",
        "pts = [Point(x, y) for x in xs for y in ys]\n",
        "GERMANY_GRID = gpd.GeoDataFrame(\n",
        "    geometry=[p for p in pts if GERMANY_POLY.contains(p) or GERMANY_POLY.touches(p)],\n",
        "    crs=GERMANY.crs\n",
        ")\n",
        "\n",
        "# Map categories from benefit_gdf to the full grid (no spatial join with points!)\n",
        "def _ck(p):  # coordinate key\n",
        "    return (round(p.x, 5), round(p.y, 5))\n",
        "\n",
        "cat_lookup = dict(zip(\n",
        "    benefit_gdf.geometry.apply(_ck),\n",
        "    benefit_gdf['benefit_category']\n",
        "))\n",
        "\n",
        "GERMANY_GRID['benefit_category'] = GERMANY_GRID.geometry.apply(\n",
        "    lambda g: cat_lookup.get(_ck(g), \"Likely irrelevant (<10 min)\")\n",
        ")\n",
        "\n",
        "print(f\"Total Germany grid points: {len(GERMANY_GRID):,}\")\n",
        "print(\"Category counts (points):\")\n",
        "print(GERMANY_GRID['benefit_category'].value_counts())\n",
        "\n",
        "# Annotate with SMOD\n",
        "print(\"üèôÔ∏è Annotating grid with SMOD urban/rural classes ‚Ä¶\")\n",
        "annotated = gs.urban_rural_annotation.add_smod_labels(GERMANY_GRID, str(SMOD_RASTER))\n",
        "print(\"‚úÖ Annotation done\")\n",
        "\n",
        "# Quick check\n",
        "ur_counts = annotated['urban_rural'].value_counts()\n",
        "print(\"Urban/Rural distribution (all points):\")\n",
        "print(ur_counts.apply(lambda v: f\"{v:,} ({v/len(annotated)*100:.1f}%)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Generating Urban/Rural Summary by Benefit Category\n",
            "======================================================================\n",
            "\n",
            "üë• Absolute counts:\n",
            "urban_rural                      other      rural     urban\n",
            "benefit_category                                           \n",
            "High (30+ min)                    47.0   34,966.0   2,404.0\n",
            "Medium (20-30 min)                93.0   68,063.0   4,303.0\n",
            "Low (10-20 min)                  242.0  106,732.0   9,700.0\n",
            "Only CT reachable within 60 min  164.0   19,760.0     238.0\n",
            "Neither reachable within 60 min  833.0    5,548.0     188.0\n",
            "Likely irrelevant (<10 min)      476.0  177,871.0  27,721.0\n",
            "\n",
            "üìä Percent within each category:\n",
            "urban_rural                      other  rural  urban\n",
            "benefit_category                                    \n",
            "High (30+ min)                     0.1   93.4    6.4\n",
            "Medium (20-30 min)                 0.1   93.9    5.9\n",
            "Low (10-20 min)                    0.2   91.5    8.3\n",
            "Only CT reachable within 60 min    0.8   98.0    1.2\n",
            "Neither reachable within 60 min   12.7   84.5    2.9\n",
            "Likely irrelevant (<10 min)        0.2   86.3   13.5\n",
            "\n",
            "üíæ Saved CSVs: urban_rural_by_category_abs.csv, urban_rural_by_category_pct.csv\n",
            "\n",
            "üìã Markdown (percent table):\n",
            "| benefit_category                |   other |   rural |   urban |\n",
            "|:--------------------------------|--------:|--------:|--------:|\n",
            "| High (30+ min)                  |     0.1 |    93.4 |     6.4 |\n",
            "| Medium (20-30 min)              |     0.1 |    93.9 |     5.9 |\n",
            "| Low (10-20 min)                 |     0.2 |    91.5 |     8.3 |\n",
            "| Only CT reachable within 60 min |     0.8 |    98   |     1.2 |\n",
            "| Neither reachable within 60 min |    12.7 |    84.5 |     2.9 |\n",
            "| Likely irrelevant (<10 min)     |     0.2 |    86.3 |    13.5 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/l_/hnp4n5y13k3dbz2xfjjz44p00000gn/T/ipykernel_8312/1045961716.py:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(summary_abs.applymap(lambda x: f\"{x:,}\"))\n"
          ]
        }
      ],
      "source": [
        "# ---- 5. Urban/Rural summary table (absolute + %) by benefit category ----\n",
        "print(\"üìã Generating Urban/Rural Summary by Benefit Category\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "CATEGORY_ORDER = [\n",
        "    \"High (30+ min)\",\n",
        "    \"Medium (20-30 min)\",\n",
        "    \"Low (10-20 min)\",\n",
        "    \"Only CT reachable within 60 min\",\n",
        "    \"Neither reachable within 60 min\",\n",
        "    \"Likely irrelevant (<10 min)\",\n",
        "]\n",
        "\n",
        "# Counts\n",
        "cnt = (annotated\n",
        "       .groupby(['benefit_category', 'urban_rural'])\n",
        "       .size()\n",
        "       .rename('n')\n",
        "       .reset_index())\n",
        "\n",
        "# Totals per category & percentages\n",
        "totals = cnt.groupby('benefit_category')['n'].sum().rename('cat_total')\n",
        "cnt = cnt.merge(totals, on='benefit_category')\n",
        "cnt['pct_within_cat'] = (cnt['n'] / cnt['cat_total'] * 100).round(1)\n",
        "\n",
        "# Wide tables\n",
        "summary_abs = (cnt.pivot_table(index='benefit_category',\n",
        "                               columns='urban_rural',\n",
        "                               values='n',\n",
        "                               fill_value=0)\n",
        "                 .reindex(CATEGORY_ORDER))\n",
        "summary_pct = (cnt.pivot_table(index='benefit_category',\n",
        "                               columns='urban_rural',\n",
        "                               values='pct_within_cat',\n",
        "                               fill_value=0)\n",
        "                 .reindex(CATEGORY_ORDER))\n",
        "\n",
        "pd.set_option('display.width', None)\n",
        "print(\"\\nüë• Absolute counts:\")\n",
        "print(summary_abs.applymap(lambda x: f\"{x:,}\"))\n",
        "\n",
        "print(\"\\nüìä Percent within each category:\")\n",
        "print(summary_pct)\n",
        "\n",
        "# Save\n",
        "summary_abs.to_csv(\"urban_rural_by_category_abs.csv\")\n",
        "summary_pct.to_csv(\"urban_rural_by_category_pct.csv\")\n",
        "print(\"\\nüíæ Saved CSVs: urban_rural_by_category_abs.csv, urban_rural_by_category_pct.csv\")\n",
        "\n",
        "# Markdown export\n",
        "print(\"\\nüìã Markdown (percent table):\")\n",
        "print(summary_pct.to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Analysis\n",
        "\n",
        "Generate summary tables showing the urban/rural breakdown by benefit category:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Generating Urban/Rural Summary by Benefit Category\n",
            "=======================================================\n",
            "\n",
            "üìä Summary Table:\n",
            "urban_rural                      other   rural  urban   total  pct_urban  pct_rural  pct_other\n",
            "benefit_category                                                                              \n",
            "High (30+ min)                      47   34966   2404   37417        6.4       93.4        0.1\n",
            "Likely irrelevant (<10 min)        476  177871  27721  206068       13.5       86.3        0.2\n",
            "Low (10-20 min)                    242  106732   9700  116674        8.3       91.5        0.2\n",
            "Medium (20-30 min)                  93   68063   4303   72459        5.9       93.9        0.1\n",
            "Neither reachable within 60 min    833    5548    188    6569        2.9       84.5       12.7\n",
            "Only CT reachable within 60 min    164   19760    238   20162        1.2       98.0        0.8\n",
            "\n",
            "üìã Markdown format (for easy copying):\n",
            "| benefit_category                |   other |   rural |   urban |   total |   pct_urban |   pct_rural |   pct_other |\n",
            "|:--------------------------------|--------:|--------:|--------:|--------:|------------:|------------:|------------:|\n",
            "| High (30+ min)                  |      47 |   34966 |    2404 |   37417 |         6.4 |        93.4 |         0.1 |\n",
            "| Likely irrelevant (<10 min)     |     476 |  177871 |   27721 |  206068 |        13.5 |        86.3 |         0.2 |\n",
            "| Low (10-20 min)                 |     242 |  106732 |    9700 |  116674 |         8.3 |        91.5 |         0.2 |\n",
            "| Medium (20-30 min)              |      93 |   68063 |    4303 |   72459 |         5.9 |        93.9 |         0.1 |\n",
            "| Neither reachable within 60 min |     833 |    5548 |     188 |    6569 |         2.9 |        84.5 |        12.7 |\n",
            "| Only CT reachable within 60 min |     164 |   19760 |     238 |   20162 |         1.2 |        98   |         0.8 |\n",
            "\n",
            "üíæ Summary exported to: benefit_urban_rural_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# ---- 5. Build the summary percentage table ----\n",
        "\n",
        "print(\"üìã Generating Urban/Rural Summary by Benefit Category\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "summary = gs.urban_rural_annotation.summary_by_category(annotated)\n",
        "\n",
        "# Display the table in a nice format\n",
        "print(\"\\nüìä Summary Table:\")\n",
        "print(summary.to_string())\n",
        "\n",
        "# Also display as markdown for better formatting\n",
        "print(\"\\nüìã Markdown format (for easy copying):\")\n",
        "print(summary.to_markdown())\n",
        "\n",
        "# Export to CSV\n",
        "output_file = \"benefit_urban_rural_summary.csv\"\n",
        "summary.to_csv(output_file)\n",
        "print(f\"\\nüíæ Summary exported to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Insights\n",
        "\n",
        "Generate some key insights from the analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üí° Key Insights from Urban/Rural Analysis\n",
            "=============================================\n",
            "\n",
            "üåç Overall Distribution:\n",
            "   Urban areas: 44,554 points (9.7%)\n",
            "   Rural areas: 412,940 points (89.9%)\n",
            "   Other areas: 1,855 points (0.4%)\n",
            "\n",
            "üèôÔ∏è Most Urban Benefit Categories:\n",
            "   Likely irrelevant (<10 min): 13.5% urban (27,721 points)\n",
            "   Low (10-20 min): 8.3% urban (9,700 points)\n",
            "   High (30+ min): 6.4% urban (2,404 points)\n",
            "\n",
            "üåæ Most Rural Benefit Categories:\n",
            "   Only CT reachable within 60 min: 98.0% rural (19,760 points)\n",
            "   Medium (20-30 min): 93.9% rural (68,063 points)\n",
            "   High (30+ min): 93.4% rural (34,966 points)\n",
            "\n",
            "üèúÔ∏è Healthcare Desert Analysis:\n",
            "   Total healthcare desert areas: 6,569.0 points\n",
            "   Rural healthcare deserts: 84.5%\n",
            "   Urban healthcare deserts: 2.9%\n",
            "\n",
            "‚úÖ Analysis complete! Check the exported CSV files for detailed results.\n"
          ]
        }
      ],
      "source": [
        "# ---- 6. Generate key insights ----\n",
        "\n",
        "print(\"üí° Key Insights from Urban/Rural Analysis\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Overall urban vs rural distribution\n",
        "total_urban = summary['urban'].sum() if 'urban' in summary.columns else 0\n",
        "total_rural = summary['rural'].sum() if 'rural' in summary.columns else 0\n",
        "total_other = summary['other'].sum() if 'other' in summary.columns else 0\n",
        "total_points = total_urban + total_rural + total_other\n",
        "\n",
        "print(f\"\\nüåç Overall Distribution:\")\n",
        "print(f\"   Urban areas: {total_urban:,} points ({total_urban/total_points*100:.1f}%)\")\n",
        "print(f\"   Rural areas: {total_rural:,} points ({total_rural/total_points*100:.1f}%)\")\n",
        "print(f\"   Other areas: {total_other:,} points ({total_other/total_points*100:.1f}%)\")\n",
        "\n",
        "# Find which benefit categories are most rural vs urban\n",
        "print(f\"\\nüèôÔ∏è Most Urban Benefit Categories:\")\n",
        "if 'pct_urban' in summary.columns:\n",
        "    urban_sorted = summary.sort_values('pct_urban', ascending=False)\n",
        "    for category in urban_sorted.index[:3]:\n",
        "        pct = urban_sorted.loc[category, 'pct_urban']\n",
        "        count = urban_sorted.loc[category, 'urban'] if 'urban' in urban_sorted.columns else 0\n",
        "        print(f\"   {category}: {pct:.1f}% urban ({count:,} points)\")\n",
        "\n",
        "print(f\"\\nüåæ Most Rural Benefit Categories:\")\n",
        "if 'pct_rural' in summary.columns:\n",
        "    rural_sorted = summary.sort_values('pct_rural', ascending=False)\n",
        "    for category in rural_sorted.index[:3]:\n",
        "        pct = rural_sorted.loc[category, 'pct_rural']\n",
        "        count = rural_sorted.loc[category, 'rural'] if 'rural' in rural_sorted.columns else 0\n",
        "        print(f\"   {category}: {pct:.1f}% rural ({count:,} points)\")\n",
        "\n",
        "# Healthcare desert analysis\n",
        "if \"Neither reachable within 60 min\" in summary.index:\n",
        "    desert_row = summary.loc[\"Neither reachable within 60 min\"]\n",
        "    print(f\"\\nüèúÔ∏è Healthcare Desert Analysis:\")\n",
        "    print(f\"   Total healthcare desert areas: {desert_row['total']:,} points\")\n",
        "    if 'pct_rural' in desert_row:\n",
        "        print(f\"   Rural healthcare deserts: {desert_row['pct_rural']:.1f}%\")\n",
        "    if 'pct_urban' in desert_row:\n",
        "        print(f\"   Urban healthcare deserts: {desert_row['pct_urban']:.1f}%\")\n",
        "\n",
        "print(f\"\\n‚úÖ Analysis complete! Check the exported CSV files for detailed results.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isochrone Coverage Analysis\n",
        "\n",
        "In addition to analyzing specific benefit points, we can examine the raw isochrone coverage areas themselves. This provides insights into the spatial extent of healthcare accessibility across urban and rural areas for different time thresholds.\n",
        "\n",
        "### What This Analysis Shows\n",
        "\n",
        "- **Coverage patterns** - How much area is covered by each time bin\n",
        "- **Urban vs rural accessibility** - Whether urban or rural areas dominate coverage zones  \n",
        "- **Facility type comparison** - Differences between stroke units and CT hospitals\n",
        "- **Time-distance relationships** - How coverage expands with time thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading isochrone data for analysis...\n",
            "   This may take a moment as we process thousands of polygons...\n",
            "üì¶ Loaded 349 polygons for Stroke Units 15min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 30min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 45min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 60min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 15min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 30min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 45min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 60min\n",
            "üì¶ Loaded 463 polygons for Extended Stroke Units 15min\n",
            "üì¶ Loaded 463 polygons for Extended Stroke Units 30min\n",
            "üì¶ Loaded 463 polygons for Extended Stroke Units 45min\n",
            "üì¶ Loaded 463 polygons for Extended Stroke Units 60min\n",
            "\n",
            "‚úÖ Loaded isochrone data:\n",
            "   Stroke units: 1,396 isochrone polygons\n",
            "   CT hospitals: 5,900 isochrone polygons\n",
            "   Extended stroke units: 1,852 isochrone polygons\n",
            "   Total: 9,148 isochrone polygons\n",
            "\n",
            "üìä Isochrone Coverage Summary:\n",
            "   Stroke Units:\n",
            "     15 min: 349 polygons, 75,255 km¬≤ total, 215.6 km¬≤ avg\n",
            "     30 min: 349 polygons, 615,651 km¬≤ total, 1764.0 km¬≤ avg\n",
            "     45 min: 349 polygons, 1,998,442 km¬≤ total, 5726.2 km¬≤ avg\n",
            "     60 min: 349 polygons, 4,438,640 km¬≤ total, 12718.2 km¬≤ avg\n",
            "   CT Hospitals:\n",
            "     15 min: 1,475 polygons, 336,688 km¬≤ total, 228.3 km¬≤ avg\n",
            "     30 min: 1,475 polygons, 2,545,211 km¬≤ total, 1725.6 km¬≤ avg\n",
            "     45 min: 1,475 polygons, 8,185,864 km¬≤ total, 5549.7 km¬≤ avg\n",
            "     60 min: 1,475 polygons, 18,186,096 km¬≤ total, 12329.6 km¬≤ avg\n",
            "   Extended Stroke Units:\n",
            "     15 min: 463 polygons, 101,240 km¬≤ total, 218.7 km¬≤ avg\n",
            "     30 min: 463 polygons, 806,187 km¬≤ total, 1741.2 km¬≤ avg\n",
            "     45 min: 463 polygons, 2,590,093 km¬≤ total, 5594.2 km¬≤ avg\n",
            "     60 min: 463 polygons, 5,740,280 km¬≤ total, 12398.0 km¬≤ avg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/geostroke/data.py:79: RuntimeWarning: stroke_units_extended_geocoded.csv found in project root; consider moving it to /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ---- 7. Load and Process Isochrone Data ----\n",
        "\n",
        "def load_isochrones_as_gdf(suffix: str, facility_type: str, time_bins: list = None) -> gpd.GeoDataFrame:\n",
        "    \"\"\"Load isochrone polygons and convert to GeoDataFrame with metadata.\"\"\"\n",
        "    if time_bins is None:\n",
        "        time_bins = [15, 30, 45, 60]  # Focus on key time bands for visualization\n",
        "    \n",
        "    # Load facility data to get facility information\n",
        "    if suffix == \"_all_CTs\":\n",
        "        facilities_df = gs.data.load_hospitals_ct()\n",
        "    elif suffix == \"_extended_stroke\":\n",
        "        try:\n",
        "            facilities_df = gs.data.load_extended_stroke_units()\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"‚ö†Ô∏è  Extended stroke units not available: {e}\")\n",
        "            print(f\"   Please run additional_stroke_centers.ipynb to generate the extended dataset.\")\n",
        "            return gpd.GeoDataFrame(columns=['geometry', 'time_bin', 'facility_type', 'facility_id', \n",
        "                                           'facility_name', 'facility_lat', 'facility_lon', 'area_km2'], \n",
        "                                   crs=\"EPSG:4326\")\n",
        "    else:\n",
        "        facilities_df = gs.data.load_stroke_units()\n",
        "    \n",
        "    rows = []\n",
        "    \n",
        "    for time_bin in time_bins:\n",
        "        cache_path = gs.config.DATA_DIR / f\"poly{time_bin}{suffix}.pkl\"\n",
        "        \n",
        "        if cache_path.exists():\n",
        "            with open(cache_path, \"rb\") as f:\n",
        "                polygons = pickle.load(f)\n",
        "            \n",
        "            print(f\"üì¶ Loaded {len(polygons)} polygons for {facility_type} {time_bin}min\")\n",
        "            \n",
        "            # Create rows for each polygon with metadata\n",
        "            for i, polygon in enumerate(polygons):\n",
        "                if polygon and not polygon.is_empty:  # Skip empty/invalid polygons\n",
        "                    # Get facility info if available\n",
        "                    facility_name = \"Unknown\"\n",
        "                    facility_lat = None\n",
        "                    facility_lon = None\n",
        "                    \n",
        "                    if i < len(facilities_df):\n",
        "                        facility_row = facilities_df.iloc[i]\n",
        "                        facility_name = facility_row.get('name', f'Facility_{i}')\n",
        "                        facility_lat = facility_row.get('latitude')\n",
        "                        facility_lon = facility_row.get('longitude')\n",
        "                    \n",
        "                    rows.append({\n",
        "                        'geometry': polygon,\n",
        "                        'time_bin': time_bin,\n",
        "                        'facility_type': facility_type,\n",
        "                        'facility_id': i,\n",
        "                        'facility_name': facility_name,\n",
        "                        'facility_lat': facility_lat,\n",
        "                        'facility_lon': facility_lon,\n",
        "                        'area_km2': polygon.area * 111**2,  # Rough conversion to km¬≤\n",
        "                    })\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Missing isochrone file: {cache_path}\")\n",
        "    \n",
        "    if rows:\n",
        "        return gpd.GeoDataFrame(rows, crs=\"EPSG:4326\")\n",
        "    else:\n",
        "        return gpd.GeoDataFrame(columns=['geometry', 'time_bin', 'facility_type', 'facility_id', \n",
        "                                       'facility_name', 'facility_lat', 'facility_lon', 'area_km2'], \n",
        "                               crs=\"EPSG:4326\")\n",
        "\n",
        "print(\"üîÑ Loading isochrone data for analysis...\")\n",
        "print(\"   This may take a moment as we process thousands of polygons...\")\n",
        "\n",
        "# Load isochrones for both facility types\n",
        "stroke_isochrones = load_isochrones_as_gdf(\"\", \"Stroke Units\")\n",
        "ct_isochrones = load_isochrones_as_gdf(\"_all_CTs\", \"CT Hospitals\")\n",
        "extended_stroke_isochrones = load_isochrones_as_gdf(\"_extended_stroke\", \"Extended Stroke Units\")\n",
        "\n",
        "# Combine both datasets\n",
        "combined_data = pd.concat([stroke_isochrones, ct_isochrones, extended_stroke_isochrones], ignore_index=True)\n",
        "\n",
        "all_isochrones = gpd.GeoDataFrame(combined_data, crs=\"EPSG:4326\")\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded isochrone data:\")\n",
        "print(f\"   Stroke units: {len(stroke_isochrones):,} isochrone polygons\")\n",
        "print(f\"   CT hospitals: {len(ct_isochrones):,} isochrone polygons\")\n",
        "print(f\"   Extended stroke units: {len(extended_stroke_isochrones):,} isochrone polygons\")\n",
        "print(f\"   Total: {len(all_isochrones):,} isochrone polygons\")\n",
        "\n",
        "\n",
        "# Display basic statistics\n",
        "print(f\"\\nüìä Isochrone Coverage Summary:\")\n",
        "for facility_type in all_isochrones['facility_type'].unique():\n",
        "    subset = all_isochrones[all_isochrones['facility_type'] == facility_type]\n",
        "    print(f\"   {facility_type}:\")\n",
        "    for time_bin in sorted(subset['time_bin'].unique()):\n",
        "        time_subset = subset[subset['time_bin'] == time_bin]\n",
        "        total_area = time_subset['area_km2'].sum()\n",
        "        avg_area = time_subset['area_km2'].mean()\n",
        "        print(f\"     {time_bin} min: {len(time_subset):,} polygons, {total_area:,.0f} km¬≤ total, {avg_area:.1f} km¬≤ avg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Using cached equal-area SMOD raster: GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0_EA.tif\n",
            "üßÆ Dissolving isochrones by facility type + time band ‚Ä¶\n",
            "   12 union polygons ready\n",
            "üèôÔ∏è  Zonal statistics ‚Ä¶ (centre-pixel test)\n",
            "\n",
            "üîé Polygon area vs raster-derived area (km¬≤):\n",
            "        facility_type  time_bin area_km2 total_km2 area_diff_pct\n",
            "         CT Hospitals        15   130656    130696          +0.0\n",
            "         CT Hospitals        30   320190    320046          -0.0\n",
            "         CT Hospitals        45   352128    352069          -0.0\n",
            "         CT Hospitals        60   354706    354669          -0.0\n",
            "Extended Stroke Units        15    52400     52364          -0.1\n",
            "Extended Stroke Units        30   226113    226106          -0.0\n",
            "Extended Stroke Units        45   320398    320313          -0.0\n",
            "Extended Stroke Units        60   347818    347795          -0.0\n",
            "         Stroke Units        15    41404     41372          -0.1\n",
            "         Stroke Units        30   195443    195465          +0.0\n",
            "         Stroke Units        45   301312    301211          -0.0\n",
            "         Stroke Units        60   338723    338703          -0.0\n",
            "\n",
            "üìã Union coverage ‚Äì absolute areas (km¬≤):\n",
            "        facility_type  time_bin total_km2 urban_km2 rural_km2 other_km2\n",
            "         CT Hospitals        15    130696     27637    103043        16\n",
            "         CT Hospitals        30    320046     34892    284712       442\n",
            "         CT Hospitals        45    352069     35130    316190       749\n",
            "         CT Hospitals        60    354669     35148    318433      1088\n",
            "Extended Stroke Units        15     52364     17224     35135         5\n",
            "Extended Stroke Units        30    226106     32311    193531       264\n",
            "Extended Stroke Units        45    320313     34684    285012       617\n",
            "Extended Stroke Units        60    347795     35076    311941       778\n",
            "         Stroke Units        15     41372     15088     26280         4\n",
            "         Stroke Units        30    195465     30573    164643       249\n",
            "         Stroke Units        45    301211     34214    266443       554\n",
            "         Stroke Units        60    338703     34922    303014       767\n",
            "\n",
            "üìä Percent urban/rural within each union polygon:\n",
            "        facility_type  time_bin  pct_urban  pct_rural  pct_other\n",
            "         CT Hospitals        15       21.1       78.8        0.0\n",
            "         CT Hospitals        30       10.9       89.0        0.1\n",
            "         CT Hospitals        45       10.0       89.8        0.2\n",
            "         CT Hospitals        60        9.9       89.8        0.3\n",
            "Extended Stroke Units        15       32.9       67.1        0.0\n",
            "Extended Stroke Units        30       14.3       85.6        0.1\n",
            "Extended Stroke Units        45       10.8       89.0        0.2\n",
            "Extended Stroke Units        60       10.1       89.7        0.2\n",
            "         Stroke Units        15       36.5       63.5        0.0\n",
            "         Stroke Units        30       15.6       84.2        0.1\n",
            "         Stroke Units        45       11.4       88.5        0.2\n",
            "         Stroke Units        60       10.3       89.5        0.2\n",
            "\n",
            "üíæ Writing CSVs ‚Ä¶\n",
            "   ‚Ä¢ union_isochrones_area_abs.csv (absolute km¬≤)\n",
            "   ‚Ä¢ union_isochrones_area_pct.csv (percentages)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Union isochrones per *facility type* and *time bin* ‚Äì **Version 3 (debug)**\n",
        "=======================================================================\n",
        "This revision fixes the >100 % artefacts you saw:\n",
        "\n",
        "* **all_touched=False** ‚Äì we now count only pixels whose *centre* lies in\n",
        "the polygon, eliminating boundary over-counting.\n",
        "* **Pixel ‚Üí km¬≤ conversion** ‚Äì absolute urban/rural areas are derived from\n",
        "  `pixel_count √ó pixel_area`, so the km¬≤ sums line up with the polygon\n",
        "  surface.\n",
        "* **Debug block** ‚Äì prints a side-by-side comparison of polygon area vs\n",
        "  raster-derived area so you can spot any remaining discrepancy.\n",
        "\n",
        "Drop this cell *after* you create `all_isochrones` (immediately after cell 2).\n",
        "It leaves the `unions` GeoDataFrame in memory and writes two CSVs mirroring\n",
        "your earlier grid analysis.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "import rasterstats as rs\n",
        "\n",
        "EA_CRS = \"EPSG:6933\"   # Cylindrical Equal-Area (m)\n",
        "EA_RES = 1000           # 1 km √ó 1 km grid ‚áí 1 pixel ‚âà 1 km¬≤\n",
        "PIXEL_AREA_KM2 = (EA_RES ** 2) / 1e6\n",
        "\n",
        "#############################################\n",
        "# 0. Re-project SMOD raster to equal-area CRS\n",
        "#############################################\n",
        "SMOD_EA = Path(str(SMOD_RASTER).replace(\".tif\", \"_EA.tif\"))\n",
        "if not SMOD_EA.exists():\n",
        "    print(\"üîÑ Re-projecting SMOD raster to equal-area ‚Ä¶\")\n",
        "    with rasterio.open(SMOD_RASTER) as src:\n",
        "        transform, width, height = calculate_default_transform(\n",
        "            src.crs, EA_CRS, src.width, src.height,\n",
        "            *src.bounds, resolution=EA_RES\n",
        "        )\n",
        "        meta = src.meta.copy()\n",
        "        meta.update({\"crs\": EA_CRS, \"transform\": transform,\n",
        "                     \"width\": width, \"height\": height})\n",
        "        with rasterio.open(SMOD_EA, \"w\", **meta) as dst:\n",
        "            for i in range(1, src.count + 1):\n",
        "                reproject(\n",
        "                    rasterio.band(src, i), rasterio.band(dst, i),\n",
        "                    src_transform=src.transform, src_crs=src.crs,\n",
        "                    dst_transform=transform, dst_crs=EA_CRS,\n",
        "                    resampling=Resampling.nearest,\n",
        "                )\n",
        "    print(f\"   ‚Üí Saved {SMOD_EA.name}\")\n",
        "else:\n",
        "    print(f\"üì¶ Using cached equal-area SMOD raster: {SMOD_EA.name}\")\n",
        "\n",
        "#####################\n",
        "# 1. Union polygons #\n",
        "#####################\n",
        "print(\"üßÆ Dissolving isochrones by facility type + time band ‚Ä¶\")\n",
        "iso_eq = all_isochrones.to_crs(EA_CRS)\n",
        "\n",
        "after_union = (iso_eq.dissolve(by=[\"facility_type\", \"time_bin\"])  # GeoSeries\n",
        "                        .reset_index())\n",
        "after_union[\"area_km2\"] = after_union.geometry.area / 1e6  # m¬≤ ‚Üí km¬≤\n",
        "print(f\"   {len(after_union):,} union polygons ready\")\n",
        "\n",
        "############################################\n",
        "# 2. Zonal statistics on equal-area raster  #\n",
        "############################################\n",
        "print(\"üèôÔ∏è  Zonal statistics ‚Ä¶ (centre-pixel test)\")\n",
        "\n",
        "URBAN_CODES = {30, 23,22,21}          # GHSL-SMOD urban\n",
        "RURAL_CODES = {13,12,11}  # rural / peri-urban\n",
        "OTHER_CODES = {10}\n",
        "\n",
        "zs = rs.zonal_stats(\n",
        "    after_union.geometry, str(SMOD_EA), categorical=True, nodata=0,\n",
        "    all_touched=False  # centre of pixel must fall within polygon\n",
        ")\n",
        "\n",
        "after_union[\"urban_cells\"] = [sum(z.get(c, 0) for c in URBAN_CODES) for z in zs]\n",
        "after_union[\"rural_cells\"] = [sum(z.get(c, 0) for c in RURAL_CODES) for z in zs]\n",
        "after_union[\"other_cells\"] = [sum(z.get(c, 0) for c in OTHER_CODES) for z in zs]\n",
        "after_union[\"total_cells\"] = after_union[\"urban_cells\"] + after_union[\"rural_cells\"] + after_union[\"other_cells\"]\n",
        "\n",
        "# Convert counts to km¬≤\n",
        "for col in [\"urban_cells\", \"rural_cells\", \"other_cells\", \"total_cells\"]:\n",
        "    after_union[col.replace(\"cells\", \"km2\")] = after_union[col] * PIXEL_AREA_KM2\n",
        "\n",
        "# Percentages\n",
        "after_union[\"pct_urban\"] = (\n",
        "    after_union[\"urban_km2\"] / after_union[\"total_km2\"] * 100\n",
        ").round(1)\n",
        "after_union[\"pct_rural\"] = (\n",
        "    after_union[\"rural_km2\"] / after_union[\"total_km2\"] * 100\n",
        ").round(1)\n",
        "after_union[\"pct_other\"] = (\n",
        "    after_union[\"other_km2\"] / after_union[\"total_km2\"] * 100\n",
        ").round(1)\n",
        "\n",
        "##########################\n",
        "# 3. Debug consistency üö¶ #\n",
        "##########################\n",
        "after_union[\"area_diff_pct\"] = ((after_union[\"total_km2\"] - after_union[\"area_km2\"]) /\n",
        "                                 after_union[\"area_km2\"] * 100).round(1)\n",
        "\n",
        "print(\"\\nüîé Polygon area vs raster-derived area (km¬≤):\")\n",
        "print(after_union[[\"facility_type\", \"time_bin\", \"area_km2\", \"total_km2\", \"area_diff_pct\"]]\n",
        "      .to_string(index=False, formatters={\n",
        "          \"area_km2\": \"{:.0f}\".format,\n",
        "          \"total_km2\": \"{:.0f}\".format,\n",
        "          \"area_diff_pct\": \"{:+.1f}\".format,\n",
        "      }))\n",
        "\n",
        "###################################################\n",
        "# 4. Pretty print & write tidy CSVs               #\n",
        "###################################################\n",
        "print(\"\\nüìã Union coverage ‚Äì absolute areas (km¬≤):\")\n",
        "abs_cols = [\"facility_type\", \"time_bin\", \"total_km2\", \"urban_km2\", \"rural_km2\", \"other_km2\"]\n",
        "print(after_union[abs_cols].to_string(index=False, formatters={\n",
        "    \"total_km2\": \"{:.0f}\".format,\n",
        "    \"urban_km2\": \"{:.0f}\".format,\n",
        "    \"rural_km2\": \"{:.0f}\".format,\n",
        "    \"other_km2\": \"{:.0f}\".format,\n",
        "}))\n",
        "\n",
        "print(\"\\nüìä Percent urban/rural within each union polygon:\")\n",
        "print(after_union[[\"facility_type\", \"time_bin\", \"pct_urban\", \"pct_rural\", \"pct_other\"]]\n",
        "      .to_string(index=False))\n",
        "\n",
        "print(\"\\nüíæ Writing CSVs ‚Ä¶\")\n",
        "after_union[abs_cols].to_csv(\"union_isochrones_area_abs.csv\", index=False)\n",
        "after_union[[\"facility_type\", \"time_bin\", \"pct_urban\", \"pct_rural\", \"pct_other\"]].to_csv(\"union_isochrones_area_pct.csv\", index=False)\n",
        "print(\"   ‚Ä¢ union_isochrones_area_abs.csv (absolute km¬≤)\\n   ‚Ä¢ union_isochrones_area_pct.csv (percentages)\")\n",
        "\n",
        "###############################\n",
        "# 5. Keep result in workspace #\n",
        "###############################\n",
        "# A convenient alias for downstream analysis\n",
        "unions = after_union.copy()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
