{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Urban/Rural Analysis of CT Hospital Benefits\n",
        "\n",
        "This notebook demonstrates how to analyze benefit areas by their rural/urban characteristics using the GHS-SMOD (Global Human Settlement Model - Settlement Model) raster data.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The GHS-SMOD raster classifies areas by degree of urbanization using UN standards:\n",
        "- **Urban codes**: {30, 23, 22, 21} - Cities, towns, suburban areas\n",
        "- **Rural codes**: {13, 12, 11} - Rural areas with different densities\n",
        "- **Other codes**: Water bodies, very low density areas, etc.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "1. **Benefit analysis results**: Previously generated using `geostroke.benefit` functions\n",
        "2. **GHS-SMOD raster**: Download from [GHS-SMOD webpage](https://ghsl.jrc.ec.europa.eu/ghs_smod2023.php)\n",
        "   - File: `GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif` (or similar)\n",
        "   - Place in `raw_data/` directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded geostroke version 1.0.0\n",
            "üìÅ Project root: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke\n",
            "üìÅ Data directory: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data\n"
          ]
        }
      ],
      "source": [
        "# ---- 1. Install what you might still need ----\n",
        "# pip install geopandas rasterio pandas pyproj shapely\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Set working directory to project root\n",
        "import os\n",
        "os.chdir('..')  # Go\n",
        "\n",
        "import geostroke as gs\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"‚úÖ Loaded geostroke version {gs.__version__}\")\n",
        "print(f\"üìÅ Project root: {gs.config.ROOT}\")\n",
        "print(f\"üìÅ Data directory: {gs.config.DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**Update these paths for your specific files:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç File checks:\n",
            "   Benefit file exists: ‚úÖ\n",
            "   SMOD raster exists: ‚úÖ\n",
            "   Benefit file: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data/benefit_cache/benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\n",
            "   SMOD raster: /Users/larsmasanneck/Library/CloudStorage/OneDrive-Personal/Dokumente/Research Basics and Coding Projects/Data Projects/Marc Pawlitzki/GeoStroke/raw_data/GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif\n"
          ]
        }
      ],
      "source": [
        "# ---- 2. Point to your inputs ----\n",
        "\n",
        "BENEFIT_FILE = gs.config.DATA_DIR / \"benefit_cache\" / \"benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\"  # <-- change to your actual file\n",
        "\n",
        "\n",
        "# GHS-SMOD raster path (adjust for your file)\n",
        "SMOD_RASTER = gs.config.DATA_DIR / \"GHS_SMOD_E2025_GLOBE_R2023A_54009_1000_V2_0.tif\"\n",
        "\n",
        "# Check if files exist\n",
        "print(f\"\\nüîç File checks:\")\n",
        "print(f\"   Benefit file exists: {'‚úÖ' if BENEFIT_FILE and BENEFIT_FILE.exists() else '‚ùå'}\")\n",
        "print(f\"   SMOD raster exists: {'‚úÖ' if SMOD_RASTER.exists() else '‚ùå'}\")\n",
        "\n",
        "if BENEFIT_FILE:\n",
        "    print(f\"   Benefit file: {BENEFIT_FILE}\")\n",
        "if SMOD_RASTER.exists():\n",
        "    print(f\"   SMOD raster: {SMOD_RASTER}\")\n",
        "else:\n",
        "    print(f\"   ‚ùå SMOD raster not found at: {SMOD_RASTER}\")\n",
        "    print(f\"   üì• Please download from: https://ghsl.jrc.ec.europa.eu/ghs_smod2023.php\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Generate Benefit Analysis\n",
        "\n",
        "If you don't have cached benefit results, run this cell to generate them:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Benefit file exists, will load from cache\n"
          ]
        }
      ],
      "source": [
        "# ---- Alternative: Generate benefit analysis if needed ----\n",
        "\n",
        "if not BENEFIT_FILE or not BENEFIT_FILE.exists():\n",
        "    print(\"üîÑ Generating benefit analysis (this may take several minutes)...\")\n",
        "    \n",
        "    # Quick benefit analysis with coarser resolution for demo\n",
        "    benefit_gdf = gs.benefit.calculate_time_benefits_parallel(\n",
        "        ct_penalty=0.0,\n",
        "        benefit_threshold=10.0,\n",
        "        grid_resolution=0.01,  # Coarser resolution for faster processing\n",
        "        time_bins=[5,10,15,20,25, 30,35,40, 45,50,55, 60],  # Fewer time bins\n",
        "        max_workers=4\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Generated benefit analysis with {len(benefit_gdf):,} points\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚úÖ Benefit file exists, will load from cache\")\n",
        "    benefit_gdf = None  # Will be loaded in next cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Benefit Analysis Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Loading benefit analysis from: benefit_analysis_e1f09274ca3df68bc9344be034cc005f.pkl\n",
            "   üìã Analysis parameters: {'ct_suffix': '_all_CTs', 'stroke_suffix': '', 'time_bins': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60], 'ct_penalty': 0, 'benefit_threshold': 10.0, 'grid_resolution': 0.01, 'bounds': None}\n",
            "‚úÖ Loaded 510,229 benefit points\n",
            "\n",
            "üìä Benefit Data Summary:\n",
            "   Total points: 510,229\n",
            "   Coordinate system: EPSG:4326\n",
            "   Columns: ['geometry', 'ct_time', 'stroke_time', 'time_benefit', 'benefit_category']\n",
            "\n",
            "   Benefit categories:\n",
            "     Neither reachable within 60 min: 260,954 points\n",
            "     Low (10-20 min): 117,029 points\n",
            "     Medium (20-30 min): 72,853 points\n",
            "     High (30+ min): 37,724 points\n",
            "     Only CT reachable within 60 min: 21,106 points\n",
            "     Likely irrelevant (<10 min): 563 points\n"
          ]
        }
      ],
      "source": [
        "# ---- 3. Load the benefit GeoDataFrame ----\n",
        "\n",
        "if benefit_gdf is None:  # Not generated in previous cell\n",
        "    if BENEFIT_FILE and BENEFIT_FILE.exists():\n",
        "        print(f\"üì• Loading benefit analysis from: {BENEFIT_FILE.name}\")\n",
        "        \n",
        "        if BENEFIT_FILE.suffix == \".pkl\":\n",
        "            with BENEFIT_FILE.open(\"rb\") as f:\n",
        "                cached_data = pickle.load(f)\n",
        "            \n",
        "            # Handle both old and new cache formats\n",
        "            if isinstance(cached_data, dict) and \"data\" in cached_data:\n",
        "                # New format with metadata\n",
        "                benefit_gdf = gpd.GeoDataFrame(cached_data[\"data\"], crs=\"EPSG:4326\")\n",
        "                if \"params\" in cached_data:\n",
        "                    print(f\"   üìã Analysis parameters: {cached_data['params']}\")\n",
        "            else:\n",
        "                # Old format - direct data\n",
        "                benefit_gdf = gpd.GeoDataFrame(cached_data, crs=\"EPSG:4326\")\n",
        "        else:\n",
        "            # GeoPackage or other format\n",
        "            benefit_gdf = gpd.read_file(BENEFIT_FILE)\n",
        "            \n",
        "        print(f\"‚úÖ Loaded {len(benefit_gdf):,} benefit points\")\n",
        "        \n",
        "    else:\n",
        "        raise FileNotFoundError(\"No benefit file available. Please run benefit analysis first.\")\n",
        "\n",
        "# Display basic info about the benefit data\n",
        "print(f\"\\nüìä Benefit Data Summary:\")\n",
        "print(f\"   Total points: {len(benefit_gdf):,}\")\n",
        "print(f\"   Coordinate system: {benefit_gdf.crs}\")\n",
        "print(f\"   Columns: {list(benefit_gdf.columns)}\")\n",
        "print(f\"\\n   Benefit categories:\")\n",
        "for category, count in benefit_gdf['benefit_category'].value_counts().items():\n",
        "    print(f\"     {category}: {count:,} points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Urban/Rural Annotation\n",
        "\n",
        "Now we'll add urban/rural labels to each benefit point using the GHS-SMOD raster:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Germany grid points: 459,349\n",
            "Category counts (points):\n",
            "benefit_category\n",
            "Likely irrelevant (<10 min)        206068\n",
            "Low (10-20 min)                    116674\n",
            "Medium (20-30 min)                  72459\n",
            "High (30+ min)                      37417\n",
            "Only CT reachable within 60 min     20162\n",
            "Neither reachable within 60 min      6569\n",
            "Name: count, dtype: int64\n",
            "üèôÔ∏è Annotating grid with SMOD urban/rural classes ‚Ä¶\n",
            "‚úÖ Annotation done\n",
            "Urban/Rural distribution (all points):\n",
            "urban_rural\n",
            "rural    412,940 (89.9%)\n",
            "urban      44,554 (9.7%)\n",
            "other       1,855 (0.4%)\n",
            "Name: count, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# ---- 4. Annotate every point with rural/urban classification (FIXED to include full complement) ----\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Sanity check\n",
        "if not SMOD_RASTER.exists():\n",
        "    raise FileNotFoundError(f\"SMOD raster not found at {SMOD_RASTER}\")\n",
        "\n",
        "# Germany outline & polygon\n",
        "GERMANY = gs.data.load_germany_outline()\n",
        "GERMANY_POLY = GERMANY.geometry.iloc[0]\n",
        "\n",
        "# Infer grid resolution from the cached benefit points (fallback 0.01¬∞)\n",
        "xs_u = np.sort(benefit_gdf.geometry.x.unique())\n",
        "ys_u = np.sort(benefit_gdf.geometry.y.unique())\n",
        "try:\n",
        "    dx = np.median(np.diff(xs_u))\n",
        "    dy = np.median(np.diff(ys_u))\n",
        "    GRID_RES = round(float(min(dx, dy)), 5)\n",
        "    if GRID_RES <= 0 or GRID_RES > 0.05:\n",
        "        GRID_RES = 0.01\n",
        "except Exception:\n",
        "    GRID_RES = 0.01\n",
        "\n",
        "# Build full Germany grid\n",
        "minx, miny, maxx, maxy = GERMANY.total_bounds\n",
        "xs = np.arange(minx, maxx + GRID_RES, GRID_RES)\n",
        "ys = np.arange(miny, maxy + GRID_RES, GRID_RES)\n",
        "pts = [Point(x, y) for x in xs for y in ys]\n",
        "GERMANY_GRID = gpd.GeoDataFrame(\n",
        "    geometry=[p for p in pts if GERMANY_POLY.contains(p) or GERMANY_POLY.touches(p)],\n",
        "    crs=GERMANY.crs\n",
        ")\n",
        "\n",
        "# Map categories from benefit_gdf to the full grid (no spatial join with points!)\n",
        "def _ck(p):  # coordinate key\n",
        "    return (round(p.x, 5), round(p.y, 5))\n",
        "\n",
        "cat_lookup = dict(zip(\n",
        "    benefit_gdf.geometry.apply(_ck),\n",
        "    benefit_gdf['benefit_category']\n",
        "))\n",
        "\n",
        "GERMANY_GRID['benefit_category'] = GERMANY_GRID.geometry.apply(\n",
        "    lambda g: cat_lookup.get(_ck(g), \"Likely irrelevant (<10 min)\")\n",
        ")\n",
        "\n",
        "print(f\"Total Germany grid points: {len(GERMANY_GRID):,}\")\n",
        "print(\"Category counts (points):\")\n",
        "print(GERMANY_GRID['benefit_category'].value_counts())\n",
        "\n",
        "# Annotate with SMOD\n",
        "print(\"üèôÔ∏è Annotating grid with SMOD urban/rural classes ‚Ä¶\")\n",
        "annotated = gs.urban_rural_annotation.add_smod_labels(GERMANY_GRID, str(SMOD_RASTER))\n",
        "print(\"‚úÖ Annotation done\")\n",
        "\n",
        "# Quick check\n",
        "ur_counts = annotated['urban_rural'].value_counts()\n",
        "print(\"Urban/Rural distribution (all points):\")\n",
        "print(ur_counts.apply(lambda v: f\"{v:,} ({v/len(annotated)*100:.1f}%)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Generating Urban/Rural Summary by Benefit Category\n",
            "======================================================================\n",
            "\n",
            "üë• Absolute counts:\n",
            "urban_rural                      other      rural     urban\n",
            "benefit_category                                           \n",
            "High (30+ min)                    47.0   34,966.0   2,404.0\n",
            "Medium (20-30 min)                93.0   68,063.0   4,303.0\n",
            "Low (10-20 min)                  242.0  106,732.0   9,700.0\n",
            "Only CT reachable within 60 min  164.0   19,760.0     238.0\n",
            "Neither reachable within 60 min  833.0    5,548.0     188.0\n",
            "Likely irrelevant (<10 min)      476.0  177,871.0  27,721.0\n",
            "\n",
            "üìä Percent within each category:\n",
            "urban_rural                      other  rural  urban\n",
            "benefit_category                                    \n",
            "High (30+ min)                     0.1   93.4    6.4\n",
            "Medium (20-30 min)                 0.1   93.9    5.9\n",
            "Low (10-20 min)                    0.2   91.5    8.3\n",
            "Only CT reachable within 60 min    0.8   98.0    1.2\n",
            "Neither reachable within 60 min   12.7   84.5    2.9\n",
            "Likely irrelevant (<10 min)        0.2   86.3   13.5\n",
            "\n",
            "üíæ Saved CSVs: urban_rural_by_category_abs.csv, urban_rural_by_category_pct.csv\n",
            "\n",
            "üìã Markdown (percent table):\n",
            "| benefit_category                |   other |   rural |   urban |\n",
            "|:--------------------------------|--------:|--------:|--------:|\n",
            "| High (30+ min)                  |     0.1 |    93.4 |     6.4 |\n",
            "| Medium (20-30 min)              |     0.1 |    93.9 |     5.9 |\n",
            "| Low (10-20 min)                 |     0.2 |    91.5 |     8.3 |\n",
            "| Only CT reachable within 60 min |     0.8 |    98   |     1.2 |\n",
            "| Neither reachable within 60 min |    12.7 |    84.5 |     2.9 |\n",
            "| Likely irrelevant (<10 min)     |     0.2 |    86.3 |    13.5 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/l_/hnp4n5y13k3dbz2xfjjz44p00000gn/T/ipykernel_8312/1045961716.py:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  print(summary_abs.applymap(lambda x: f\"{x:,}\"))\n"
          ]
        }
      ],
      "source": [
        "# ---- 5. Urban/Rural summary table (absolute + %) by benefit category ----\n",
        "print(\"üìã Generating Urban/Rural Summary by Benefit Category\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "CATEGORY_ORDER = [\n",
        "    \"High (30+ min)\",\n",
        "    \"Medium (20-30 min)\",\n",
        "    \"Low (10-20 min)\",\n",
        "    \"Only CT reachable within 60 min\",\n",
        "    \"Neither reachable within 60 min\",\n",
        "    \"Likely irrelevant (<10 min)\",\n",
        "]\n",
        "\n",
        "# Counts\n",
        "cnt = (annotated\n",
        "       .groupby(['benefit_category', 'urban_rural'])\n",
        "       .size()\n",
        "       .rename('n')\n",
        "       .reset_index())\n",
        "\n",
        "# Totals per category & percentages\n",
        "totals = cnt.groupby('benefit_category')['n'].sum().rename('cat_total')\n",
        "cnt = cnt.merge(totals, on='benefit_category')\n",
        "cnt['pct_within_cat'] = (cnt['n'] / cnt['cat_total'] * 100).round(1)\n",
        "\n",
        "# Wide tables\n",
        "summary_abs = (cnt.pivot_table(index='benefit_category',\n",
        "                               columns='urban_rural',\n",
        "                               values='n',\n",
        "                               fill_value=0)\n",
        "                 .reindex(CATEGORY_ORDER))\n",
        "summary_pct = (cnt.pivot_table(index='benefit_category',\n",
        "                               columns='urban_rural',\n",
        "                               values='pct_within_cat',\n",
        "                               fill_value=0)\n",
        "                 .reindex(CATEGORY_ORDER))\n",
        "\n",
        "pd.set_option('display.width', None)\n",
        "print(\"\\nüë• Absolute counts:\")\n",
        "print(summary_abs.applymap(lambda x: f\"{x:,}\"))\n",
        "\n",
        "print(\"\\nüìä Percent within each category:\")\n",
        "print(summary_pct)\n",
        "\n",
        "# Save\n",
        "summary_abs.to_csv(\"urban_rural_by_category_abs.csv\")\n",
        "summary_pct.to_csv(\"urban_rural_by_category_pct.csv\")\n",
        "print(\"\\nüíæ Saved CSVs: urban_rural_by_category_abs.csv, urban_rural_by_category_pct.csv\")\n",
        "\n",
        "# Markdown export\n",
        "print(\"\\nüìã Markdown (percent table):\")\n",
        "print(summary_pct.to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Analysis\n",
        "\n",
        "Generate summary tables showing the urban/rural breakdown by benefit category:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Generating Urban/Rural Summary by Benefit Category\n",
            "=======================================================\n",
            "\n",
            "üìä Summary Table:\n",
            "urban_rural                      other   rural  urban   total  pct_urban  pct_rural  pct_other\n",
            "benefit_category                                                                              \n",
            "High (30+ min)                      47   34966   2404   37417        6.4       93.4        0.1\n",
            "Likely irrelevant (<10 min)        476  177871  27721  206068       13.5       86.3        0.2\n",
            "Low (10-20 min)                    242  106732   9700  116674        8.3       91.5        0.2\n",
            "Medium (20-30 min)                  93   68063   4303   72459        5.9       93.9        0.1\n",
            "Neither reachable within 60 min    833    5548    188    6569        2.9       84.5       12.7\n",
            "Only CT reachable within 60 min    164   19760    238   20162        1.2       98.0        0.8\n",
            "\n",
            "üìã Markdown format (for easy copying):\n",
            "| benefit_category                |   other |   rural |   urban |   total |   pct_urban |   pct_rural |   pct_other |\n",
            "|:--------------------------------|--------:|--------:|--------:|--------:|------------:|------------:|------------:|\n",
            "| High (30+ min)                  |      47 |   34966 |    2404 |   37417 |         6.4 |        93.4 |         0.1 |\n",
            "| Likely irrelevant (<10 min)     |     476 |  177871 |   27721 |  206068 |        13.5 |        86.3 |         0.2 |\n",
            "| Low (10-20 min)                 |     242 |  106732 |    9700 |  116674 |         8.3 |        91.5 |         0.2 |\n",
            "| Medium (20-30 min)              |      93 |   68063 |    4303 |   72459 |         5.9 |        93.9 |         0.1 |\n",
            "| Neither reachable within 60 min |     833 |    5548 |     188 |    6569 |         2.9 |        84.5 |        12.7 |\n",
            "| Only CT reachable within 60 min |     164 |   19760 |     238 |   20162 |         1.2 |        98   |         0.8 |\n",
            "\n",
            "üíæ Summary exported to: benefit_urban_rural_summary.csv\n"
          ]
        }
      ],
      "source": [
        "# ---- 5. Build the summary percentage table ----\n",
        "\n",
        "print(\"üìã Generating Urban/Rural Summary by Benefit Category\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "summary = gs.urban_rural_annotation.summary_by_category(annotated)\n",
        "\n",
        "# Display the table in a nice format\n",
        "print(\"\\nüìä Summary Table:\")\n",
        "print(summary.to_string())\n",
        "\n",
        "# Also display as markdown for better formatting\n",
        "print(\"\\nüìã Markdown format (for easy copying):\")\n",
        "print(summary.to_markdown())\n",
        "\n",
        "# Export to CSV\n",
        "output_file = \"benefit_urban_rural_summary.csv\"\n",
        "summary.to_csv(output_file)\n",
        "print(f\"\\nüíæ Summary exported to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Insights\n",
        "\n",
        "Generate some key insights from the analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üí° Key Insights from Urban/Rural Analysis\n",
            "=============================================\n",
            "\n",
            "üåç Overall Distribution:\n",
            "   Urban areas: 13,949 points (6.6%)\n",
            "   Rural areas: 196,454 points (93.1%)\n",
            "   Other areas: 690 points (0.3%)\n",
            "\n",
            "üèôÔ∏è Most Urban Benefit Categories:\n",
            "   High (30+ min): 8.7% urban (1,985 points)\n",
            "   Low (10-20 min): 7.9% urban (7,658 points)\n",
            "   Medium (20-30 min): 6.8% urban (3,502 points)\n",
            "\n",
            "üåæ Most Rural Benefit Categories:\n",
            "   Only CT reachable within 60 min: 97.0% rural (19,509 points)\n",
            "   Likely irrelevant (<10 min): 96.4% rural (19,607 points)\n",
            "   Medium (20-30 min): 93.1% rural (48,022 points)\n",
            "\n",
            "‚úÖ Analysis complete! Check the exported CSV files for detailed results.\n"
          ]
        }
      ],
      "source": [
        "# ---- 6. Generate key insights ----\n",
        "\n",
        "print(\"üí° Key Insights from Urban/Rural Analysis\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Overall urban vs rural distribution\n",
        "total_urban = summary['urban'].sum() if 'urban' in summary.columns else 0\n",
        "total_rural = summary['rural'].sum() if 'rural' in summary.columns else 0\n",
        "total_other = summary['other'].sum() if 'other' in summary.columns else 0\n",
        "total_points = total_urban + total_rural + total_other\n",
        "\n",
        "print(f\"\\nüåç Overall Distribution:\")\n",
        "print(f\"   Urban areas: {total_urban:,} points ({total_urban/total_points*100:.1f}%)\")\n",
        "print(f\"   Rural areas: {total_rural:,} points ({total_rural/total_points*100:.1f}%)\")\n",
        "print(f\"   Other areas: {total_other:,} points ({total_other/total_points*100:.1f}%)\")\n",
        "\n",
        "# Find which benefit categories are most rural vs urban\n",
        "print(f\"\\nüèôÔ∏è Most Urban Benefit Categories:\")\n",
        "if 'pct_urban' in summary.columns:\n",
        "    urban_sorted = summary.sort_values('pct_urban', ascending=False)\n",
        "    for category in urban_sorted.index[:3]:\n",
        "        pct = urban_sorted.loc[category, 'pct_urban']\n",
        "        count = urban_sorted.loc[category, 'urban'] if 'urban' in urban_sorted.columns else 0\n",
        "        print(f\"   {category}: {pct:.1f}% urban ({count:,} points)\")\n",
        "\n",
        "print(f\"\\nüåæ Most Rural Benefit Categories:\")\n",
        "if 'pct_rural' in summary.columns:\n",
        "    rural_sorted = summary.sort_values('pct_rural', ascending=False)\n",
        "    for category in rural_sorted.index[:3]:\n",
        "        pct = rural_sorted.loc[category, 'pct_rural']\n",
        "        count = rural_sorted.loc[category, 'rural'] if 'rural' in rural_sorted.columns else 0\n",
        "        print(f\"   {category}: {pct:.1f}% rural ({count:,} points)\")\n",
        "\n",
        "# Healthcare desert analysis\n",
        "if \"Neither reachable within 60 min\" in summary.index:\n",
        "    desert_row = summary.loc[\"Neither reachable within 60 min\"]\n",
        "    print(f\"\\nüèúÔ∏è Healthcare Desert Analysis:\")\n",
        "    print(f\"   Total healthcare desert areas: {desert_row['total']:,} points\")\n",
        "    if 'pct_rural' in desert_row:\n",
        "        print(f\"   Rural healthcare deserts: {desert_row['pct_rural']:.1f}%\")\n",
        "    if 'pct_urban' in desert_row:\n",
        "        print(f\"   Urban healthcare deserts: {desert_row['pct_urban']:.1f}%\")\n",
        "\n",
        "print(f\"\\n‚úÖ Analysis complete! Check the exported CSV files for detailed results.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Isochrone Coverage Analysis\n",
        "\n",
        "In addition to analyzing specific benefit points, we can examine the raw isochrone coverage areas themselves. This provides insights into the spatial extent of healthcare accessibility across urban and rural areas for different time thresholds.\n",
        "\n",
        "### What This Analysis Shows\n",
        "\n",
        "- **Coverage patterns** - How much area is covered by each time bin\n",
        "- **Urban vs rural accessibility** - Whether urban or rural areas dominate coverage zones  \n",
        "- **Facility type comparison** - Differences between stroke units and CT hospitals\n",
        "- **Time-distance relationships** - How coverage expands with time thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Loading isochrone data for analysis...\n",
            "   This may take a moment as we process thousands of polygons...\n",
            "üì¶ Loaded 349 polygons for Stroke Units 15min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 30min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 45min\n",
            "üì¶ Loaded 349 polygons for Stroke Units 60min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 15min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 30min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 45min\n",
            "üì¶ Loaded 1475 polygons for CT Hospitals 60min\n",
            "\n",
            "‚úÖ Loaded isochrone data:\n",
            "   Stroke units: 1,396 isochrone polygons\n",
            "   CT hospitals: 5,900 isochrone polygons\n",
            "   Total: 7,296 isochrone polygons\n",
            "\n",
            "üìä Isochrone Coverage Summary:\n",
            "   Stroke Units:\n",
            "     15 min: 349 polygons, 75,255 km¬≤ total, 215.6 km¬≤ avg\n",
            "     30 min: 349 polygons, 615,651 km¬≤ total, 1764.0 km¬≤ avg\n",
            "     45 min: 349 polygons, 1,998,442 km¬≤ total, 5726.2 km¬≤ avg\n",
            "     60 min: 349 polygons, 4,438,640 km¬≤ total, 12718.2 km¬≤ avg\n",
            "   CT Hospitals:\n",
            "     15 min: 1,475 polygons, 336,688 km¬≤ total, 228.3 km¬≤ avg\n",
            "     30 min: 1,475 polygons, 2,545,211 km¬≤ total, 1725.6 km¬≤ avg\n",
            "     45 min: 1,475 polygons, 8,185,864 km¬≤ total, 5549.7 km¬≤ avg\n",
            "     60 min: 1,475 polygons, 18,186,096 km¬≤ total, 12329.6 km¬≤ avg\n"
          ]
        }
      ],
      "source": [
        "# ---- 7. Load and Process Isochrone Data ----\n",
        "\n",
        "def load_isochrones_as_gdf(suffix: str, facility_type: str, time_bins: list = None) -> gpd.GeoDataFrame:\n",
        "    \"\"\"Load isochrone polygons and convert to GeoDataFrame with metadata.\"\"\"\n",
        "    if time_bins is None:\n",
        "        time_bins = [15, 30, 45, 60]  # Focus on key time bands for visualization\n",
        "    \n",
        "    # Load facility data to get facility information\n",
        "    if suffix == \"_all_CTs\":\n",
        "        facilities_df = gs.data.load_hospitals_ct()\n",
        "    else:\n",
        "        facilities_df = gs.data.load_stroke_units()\n",
        "    \n",
        "    rows = []\n",
        "    \n",
        "    for time_bin in time_bins:\n",
        "        cache_path = gs.config.DATA_DIR / f\"poly{time_bin}{suffix}.pkl\"\n",
        "        \n",
        "        if cache_path.exists():\n",
        "            with open(cache_path, \"rb\") as f:\n",
        "                polygons = pickle.load(f)\n",
        "            \n",
        "            print(f\"üì¶ Loaded {len(polygons)} polygons for {facility_type} {time_bin}min\")\n",
        "            \n",
        "            # Create rows for each polygon with metadata\n",
        "            for i, polygon in enumerate(polygons):\n",
        "                if polygon and not polygon.is_empty:  # Skip empty/invalid polygons\n",
        "                    # Get facility info if available\n",
        "                    facility_name = \"Unknown\"\n",
        "                    facility_lat = None\n",
        "                    facility_lon = None\n",
        "                    \n",
        "                    if i < len(facilities_df):\n",
        "                        facility_row = facilities_df.iloc[i]\n",
        "                        facility_name = facility_row.get('name', f'Facility_{i}')\n",
        "                        facility_lat = facility_row.get('latitude')\n",
        "                        facility_lon = facility_row.get('longitude')\n",
        "                    \n",
        "                    rows.append({\n",
        "                        'geometry': polygon,\n",
        "                        'time_bin': time_bin,\n",
        "                        'facility_type': facility_type,\n",
        "                        'facility_id': i,\n",
        "                        'facility_name': facility_name,\n",
        "                        'facility_lat': facility_lat,\n",
        "                        'facility_lon': facility_lon,\n",
        "                        'area_km2': polygon.area * 111**2,  # Rough conversion to km¬≤\n",
        "                    })\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Missing isochrone file: {cache_path}\")\n",
        "    \n",
        "    if rows:\n",
        "        return gpd.GeoDataFrame(rows, crs=\"EPSG:4326\")\n",
        "    else:\n",
        "        return gpd.GeoDataFrame(columns=['geometry', 'time_bin', 'facility_type', 'facility_id', \n",
        "                                       'facility_name', 'facility_lat', 'facility_lon', 'area_km2'], \n",
        "                               crs=\"EPSG:4326\")\n",
        "\n",
        "print(\"üîÑ Loading isochrone data for analysis...\")\n",
        "print(\"   This may take a moment as we process thousands of polygons...\")\n",
        "\n",
        "# Load isochrones for both facility types\n",
        "stroke_isochrones = load_isochrones_as_gdf(\"\", \"Stroke Units\")\n",
        "ct_isochrones = load_isochrones_as_gdf(\"_all_CTs\", \"CT Hospitals\")\n",
        "\n",
        "# Combine both datasets\n",
        "combined_data = pd.concat([stroke_isochrones, ct_isochrones], ignore_index=True)\n",
        "all_isochrones = gpd.GeoDataFrame(combined_data, crs=\"EPSG:4326\")\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded isochrone data:\")\n",
        "print(f\"   Stroke units: {len(stroke_isochrones):,} isochrone polygons\")\n",
        "print(f\"   CT hospitals: {len(ct_isochrones):,} isochrone polygons\")\n",
        "print(f\"   Total: {len(all_isochrones):,} isochrone polygons\")\n",
        "\n",
        "# Display basic statistics\n",
        "print(f\"\\nüìä Isochrone Coverage Summary:\")\n",
        "for facility_type in all_isochrones['facility_type'].unique():\n",
        "    subset = all_isochrones[all_isochrones['facility_type'] == facility_type]\n",
        "    print(f\"   {facility_type}:\")\n",
        "    for time_bin in sorted(subset['time_bin'].unique()):\n",
        "        time_subset = subset[subset['time_bin'] == time_bin]\n",
        "        total_area = time_subset['area_km2'].sum()\n",
        "        avg_area = time_subset['area_km2'].mean()\n",
        "        print(f\"     {time_bin} min: {len(time_subset):,} polygons, {total_area:,.0f} km¬≤ total, {avg_area:.1f} km¬≤ avg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèôÔ∏è Applying urban/rural classification to isochrones...\n",
            "   Using polygon centroids for classification...\n",
            "‚úÖ Successfully classified 7,296 isochrone polygons\n",
            "\n",
            "üîç Isochrone Urban/Rural Distribution:\n",
            "   rural: 3,993 polygons (54.7%)\n",
            "   urban: 3,296 polygons (45.2%)\n",
            "   other: 7 polygons (0.1%)\n",
            "\n",
            "üîç Sample SMOD codes in isochrones:\n",
            "   SMOD 11: 2,211 polygons\n",
            "   SMOD 12: 1,630 polygons\n",
            "   SMOD 30: 1,564 polygons\n",
            "   SMOD 21: 1,107 polygons\n",
            "   SMOD 23: 522 polygons\n",
            "   SMOD 13: 152 polygons\n",
            "   SMOD 22: 103 polygons\n",
            "   SMOD 10: 7 polygons\n"
          ]
        }
      ],
      "source": [
        "# ---- 8. Apply Urban/Rural Classification to Isochrones ----\n",
        "\n",
        "if not SMOD_RASTER.exists():\n",
        "    print(f\"‚ùå SMOD raster not found: {SMOD_RASTER}\")\n",
        "    print(\"   Skipping urban/rural classification for isochrones\")\n",
        "    isochrones_annotated = None\n",
        "else:\n",
        "    print(\"üèôÔ∏è Applying urban/rural classification to isochrones...\")\n",
        "    print(\"   Using polygon centroids for classification...\")\n",
        "    \n",
        "    # Create representative points for classification\n",
        "    # Use centroids, but fall back to representative_point() if centroid is outside polygon\n",
        "    points = []\n",
        "    for idx, row in all_isochrones.iterrows():\n",
        "        geom = row.geometry\n",
        "        centroid = geom.centroid\n",
        "        \n",
        "        # Check if centroid is within the polygon, if not use representative_point\n",
        "        if geom.contains(centroid):\n",
        "            points.append(centroid)\n",
        "        else:\n",
        "            points.append(geom.representative_point())\n",
        "    \n",
        "    # Create a point GeoDataFrame for classification\n",
        "    points_gdf = gpd.GeoDataFrame(\n",
        "        all_isochrones.drop('geometry', axis=1), \n",
        "        geometry=points, \n",
        "        crs=all_isochrones.crs\n",
        "    )\n",
        "    \n",
        "    # Apply SMOD classification\n",
        "    points_annotated = gs.urban_rural_annotation.add_smod_labels(points_gdf, str(SMOD_RASTER))\n",
        "    \n",
        "    # Transfer urban/rural labels back to the polygon GeoDataFrame\n",
        "    isochrones_annotated = all_isochrones.copy()\n",
        "    isochrones_annotated['smod_code'] = points_annotated['smod_code']\n",
        "    isochrones_annotated['urban_rural'] = points_annotated['urban_rural']\n",
        "    \n",
        "    print(f\"‚úÖ Successfully classified {len(isochrones_annotated):,} isochrone polygons\")\n",
        "    \n",
        "    # Display classification results\n",
        "    print(f\"\\nüîç Isochrone Urban/Rural Distribution:\")\n",
        "    for category, count in isochrones_annotated['urban_rural'].value_counts().items():\n",
        "        percentage = count / len(isochrones_annotated) * 100\n",
        "        print(f\"   {category}: {count:,} polygons ({percentage:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\nüîç Sample SMOD codes in isochrones:\")\n",
        "    smod_counts = isochrones_annotated['smod_code'].value_counts().head(8)\n",
        "    for code, count in smod_counts.items():\n",
        "        print(f\"   SMOD {code}: {count:,} polygons\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Generating Isochrone Urban/Rural Summary Tables\n",
            "============================================================\n",
            "\n",
            "üìã Isochrone Coverage by Time Bin and Facility Type:\n",
            "urban_rural            other  rural  urban  total  pct_urban  pct_rural  pct_other\n",
            "time_facility                                                                     \n",
            "CT Hospitals - 15 min      1    550    924   1475       62.6       37.3        0.1\n",
            "CT Hospitals - 30 min      0    799    676   1475       45.8       54.2        0.0\n",
            "CT Hospitals - 45 min      0    957    518   1475       35.1       64.9        0.0\n",
            "CT Hospitals - 60 min      4   1003    468   1475       31.7       68.0        0.3\n",
            "Stroke Units - 15 min      1     91    257    349       73.6       26.1        0.3\n",
            "Stroke Units - 30 min      0    158    191    349       54.7       45.3        0.0\n",
            "Stroke Units - 45 min      0    217    132    349       37.8       62.2        0.0\n",
            "Stroke Units - 60 min      1    218    130    349       37.2       62.5        0.3\n",
            "\n",
            "============================================================\n",
            "üìä DETAILED BREAKDOWNS\n",
            "============================================================\n",
            "\n",
            "üìã Summary by Facility Type:\n",
            "urban_rural    other  rural  urban  total  pct_urban  pct_rural  pct_other\n",
            "facility_type                                                             \n",
            "CT Hospitals       5   3309   2586   5900       43.8       56.1        0.1\n",
            "Stroke Units       2    684    710   1396       50.9       49.0        0.1\n",
            "\n",
            "üìã Summary by Time Bin:\n",
            "urban_rural  other  rural  urban  total  pct_urban  pct_rural  pct_other\n",
            "time_bin                                                                \n",
            "15               2    641   1181   1824       64.7       35.1        0.1\n",
            "30               0    957    867   1824       47.5       52.5        0.0\n",
            "45               0   1174    650   1824       35.6       64.4        0.0\n",
            "60               5   1221    598   1824       32.8       66.9        0.3\n",
            "\n",
            "============================================================\n",
            "üìä AREA-WEIGHTED ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üìã Coverage Area (km¬≤) by Facility Type and Time:\n",
            "urban_rural                    other         rural         urban    total_area  pct_area_urban  pct_area_rural  pct_area_other\n",
            "facility_type time_bin                                                                                                        \n",
            "CT Hospitals  15          158.667009  1.390044e+05  1.975251e+05  3.366882e+05            58.7            41.3             0.0\n",
            "              30            0.000000  1.340903e+06  1.204308e+06  2.545211e+06            47.3            52.7             0.0\n",
            "              45            0.000000  4.983423e+06  3.202442e+06  8.185864e+06            39.1            60.9             0.0\n",
            "              60        50908.709729  1.153673e+07  6.598459e+06  1.818610e+07            36.3            63.4             0.3\n",
            "Stroke Units  15          168.458356  2.272667e+04  5.235980e+04  7.525493e+04            69.6            30.2             0.2\n",
            "              30            0.000000  2.762116e+05  3.394389e+05  6.156505e+05            55.1            44.9             0.0\n",
            "              45            0.000000  1.165504e+06  8.329381e+05  1.998442e+06            41.7            58.3             0.0\n",
            "              60        11952.097932  2.610164e+06  1.816524e+06  4.438640e+06            40.9            58.8             0.3\n",
            "\n",
            "üíæ Summary tables exported:\n",
            "   isochrone_urban_rural_detailed.csv - Full breakdown\n",
            "   isochrone_urban_rural_by_facility.csv - By facility type\n",
            "   isochrone_urban_rural_by_time.csv - By time bin\n",
            "   isochrone_urban_rural_area_weighted.csv - Area-weighted analysis\n"
          ]
        }
      ],
      "source": [
        "# ---- 9. Generate Isochrone Summary Tables ----\n",
        "\n",
        "if isochrones_annotated is not None:\n",
        "    print(\"üìä Generating Isochrone Urban/Rural Summary Tables\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create a combined category for analysis\n",
        "    isochrones_annotated['time_facility'] = (\n",
        "        isochrones_annotated['facility_type'].astype(str) + \" - \" + \n",
        "        isochrones_annotated['time_bin'].astype(str) + \" min\"\n",
        "    )\n",
        "    \n",
        "    # Generate summary by time and facility type\n",
        "    isochrone_summary = gs.urban_rural_annotation.summary_by_category(\n",
        "        isochrones_annotated, 'time_facility'\n",
        "    )\n",
        "    \n",
        "    print(\"\\nüìã Isochrone Coverage by Time Bin and Facility Type:\")\n",
        "    print(isochrone_summary.to_string())\n",
        "    \n",
        "    # Also create separate summaries for better analysis\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä DETAILED BREAKDOWNS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Summary by facility type only\n",
        "    facility_summary = (\n",
        "        isochrones_annotated.groupby(['facility_type', 'urban_rural'])\n",
        "        .size().unstack(fill_value=0)\n",
        "    )\n",
        "    facility_summary['total'] = facility_summary.sum(axis=1)\n",
        "    for col in ['urban', 'rural', 'other']:\n",
        "        if col in facility_summary.columns:\n",
        "            facility_summary[f'pct_{col}'] = (\n",
        "                facility_summary[col] / facility_summary['total'] * 100\n",
        "            ).round(1)\n",
        "    \n",
        "    print(\"\\nüìã Summary by Facility Type:\")\n",
        "    print(facility_summary.to_string())\n",
        "    \n",
        "    # Summary by time bin only\n",
        "    time_summary = (\n",
        "        isochrones_annotated.groupby(['time_bin', 'urban_rural'])\n",
        "        .size().unstack(fill_value=0)\n",
        "    )\n",
        "    time_summary['total'] = time_summary.sum(axis=1)\n",
        "    for col in ['urban', 'rural', 'other']:\n",
        "        if col in time_summary.columns:\n",
        "            time_summary[f'pct_{col}'] = (\n",
        "                time_summary[col] / time_summary['total'] * 100\n",
        "            ).round(1)\n",
        "    \n",
        "    print(\"\\nüìã Summary by Time Bin:\")\n",
        "    print(time_summary.to_string())\n",
        "    \n",
        "    # Area-weighted analysis\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä AREA-WEIGHTED ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Calculate total coverage area by category\n",
        "    area_summary = (\n",
        "        isochrones_annotated.groupby(['facility_type', 'time_bin', 'urban_rural'])\n",
        "        ['area_km2'].sum().unstack(fill_value=0)\n",
        "    )\n",
        "    \n",
        "    area_summary['total_area'] = area_summary.sum(axis=1)\n",
        "    for col in ['urban', 'rural', 'other']:\n",
        "        if col in area_summary.columns:\n",
        "            area_summary[f'pct_area_{col}'] = (\n",
        "                area_summary[col] / area_summary['total_area'] * 100\n",
        "            ).round(1)\n",
        "    \n",
        "    print(\"\\nüìã Coverage Area (km¬≤) by Facility Type and Time:\")\n",
        "    print(area_summary.to_string())\n",
        "    \n",
        "    # Export summary tables\n",
        "    output_base = \"isochrone_urban_rural\"\n",
        "    isochrone_summary.to_csv(f\"{output_base}_detailed.csv\")\n",
        "    facility_summary.to_csv(f\"{output_base}_by_facility.csv\") \n",
        "    time_summary.to_csv(f\"{output_base}_by_time.csv\")\n",
        "    area_summary.to_csv(f\"{output_base}_area_weighted.csv\")\n",
        "    \n",
        "    print(f\"\\nüíæ Summary tables exported:\")\n",
        "    print(f\"   {output_base}_detailed.csv - Full breakdown\")\n",
        "    print(f\"   {output_base}_by_facility.csv - By facility type\")\n",
        "    print(f\"   {output_base}_by_time.csv - By time bin\")\n",
        "    print(f\"   {output_base}_area_weighted.csv - Area-weighted analysis\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Skipping summary table generation (no annotated isochrone data)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üí° Key Insights from Isochrone Coverage Analysis\n",
            "=======================================================\n",
            "\n",
            "üåç Overall Coverage:\n",
            "   Total isochrone polygons analyzed: 7,296\n",
            "   Stroke unit isochrones: 1,396\n",
            "   CT hospital isochrones: 5,900\n",
            "\n",
            "üèôÔ∏è Urban/Rural Coverage Distribution:\n",
            "   Urban-centered isochrones: 3,296 (45.2%)\n",
            "   Rural-centered isochrones: 3,993 (54.7%)\n",
            "   Other areas: 7 (0.1%)\n",
            "\n",
            "‚è±Ô∏è Time Expansion Patterns:\n",
            "   15 min isochrones: 1,824 total, 64.7% urban, 35.1% rural, avg 225.8 km¬≤\n",
            "   30 min isochrones: 1,824 total, 47.5% urban, 52.5% rural, avg 1732.9 km¬≤\n",
            "   45 min isochrones: 1,824 total, 35.6% urban, 64.4% rural, avg 5583.5 km¬≤\n",
            "   60 min isochrones: 1,824 total, 32.8% urban, 66.9% rural, avg 12403.9 km¬≤\n",
            "\n",
            "üè• Facility Type Comparison:\n",
            "   Stroke Units:\n",
            "     1,396 isochrones (50.9% urban, 49.0% rural)\n",
            "     Total coverage: 7,127,988 km¬≤\n",
            "   CT Hospitals:\n",
            "     5,900 isochrones (43.8% urban, 56.1% rural)\n",
            "     Total coverage: 29,253,859 km¬≤\n",
            "\n",
            "üìä Coverage Insights:\n",
            "\n",
            "üåæ Highest Rural Coverage Combinations:\n",
            "   CT Hospitals - 60 min: 68.0% rural\n",
            "   CT Hospitals - 45 min: 64.9% rural\n",
            "   Stroke Units - 60 min: 62.5% rural\n",
            "\n",
            "üìè Largest Coverage Areas:\n",
            "   Niels-Stensen-Kliniken Franzis... (CT Hospitals, 60 min): 24191 km¬≤ (urban)\n",
            "   Universit√§tsklinikum Frankfurt (Stroke Units, 60 min): 23383 km¬≤ (urban)\n",
            "   Christliches Klinikum Unna WES... (Stroke Units, 60 min): 23319 km¬≤ (rural)\n",
            "\n",
            "‚úÖ Isochrone analysis complete! Check the exported CSV files for detailed results.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/l_/hnp4n5y13k3dbz2xfjjz44p00000gn/T/ipykernel_76102/1737807938.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  max_rural_coverage = isochrones_annotated.groupby(['facility_type', 'time_bin']).apply(\n"
          ]
        }
      ],
      "source": [
        "# ---- 10. Key Insights from Isochrone Analysis ----\n",
        "\n",
        "if isochrones_annotated is not None:\n",
        "    print(\"üí° Key Insights from Isochrone Coverage Analysis\")\n",
        "    print(\"=\" * 55)\n",
        "    \n",
        "    # Overall coverage patterns\n",
        "    total_isochrones = len(isochrones_annotated)\n",
        "    stroke_count = len(isochrones_annotated[isochrones_annotated['facility_type'] == 'Stroke Units'])\n",
        "    ct_count = len(isochrones_annotated[isochrones_annotated['facility_type'] == 'CT Hospitals'])\n",
        "    \n",
        "    print(f\"\\nüåç Overall Coverage:\")\n",
        "    print(f\"   Total isochrone polygons analyzed: {total_isochrones:,}\")\n",
        "    print(f\"   Stroke unit isochrones: {stroke_count:,}\")\n",
        "    print(f\"   CT hospital isochrones: {ct_count:,}\")\n",
        "    \n",
        "    # Urban vs rural distribution\n",
        "    urban_count = len(isochrones_annotated[isochrones_annotated['urban_rural'] == 'urban'])\n",
        "    rural_count = len(isochrones_annotated[isochrones_annotated['urban_rural'] == 'rural'])\n",
        "    other_count = len(isochrones_annotated[isochrones_annotated['urban_rural'] == 'other'])\n",
        "    \n",
        "    print(f\"\\nüèôÔ∏è Urban/Rural Coverage Distribution:\")\n",
        "    print(f\"   Urban-centered isochrones: {urban_count:,} ({urban_count/total_isochrones*100:.1f}%)\")\n",
        "    print(f\"   Rural-centered isochrones: {rural_count:,} ({rural_count/total_isochrones*100:.1f}%)\")\n",
        "    print(f\"   Other areas: {other_count:,} ({other_count/total_isochrones*100:.1f}%)\")\n",
        "    \n",
        "    # Time expansion patterns\n",
        "    print(f\"\\n‚è±Ô∏è Time Expansion Patterns:\")\n",
        "    for time_bin in sorted(isochrones_annotated['time_bin'].unique()):\n",
        "        time_subset = isochrones_annotated[isochrones_annotated['time_bin'] == time_bin]\n",
        "        urban_pct = len(time_subset[time_subset['urban_rural'] == 'urban']) / len(time_subset) * 100\n",
        "        rural_pct = len(time_subset[time_subset['urban_rural'] == 'rural']) / len(time_subset) * 100\n",
        "        avg_area = time_subset['area_km2'].mean()\n",
        "        \n",
        "        print(f\"   {time_bin} min isochrones: {len(time_subset):,} total, \"\n",
        "              f\"{urban_pct:.1f}% urban, {rural_pct:.1f}% rural, avg {avg_area:.1f} km¬≤\")\n",
        "    \n",
        "    # Facility type differences\n",
        "    print(f\"\\nüè• Facility Type Comparison:\")\n",
        "    for facility_type in isochrones_annotated['facility_type'].unique():\n",
        "        subset = isochrones_annotated[isochrones_annotated['facility_type'] == facility_type]\n",
        "        urban_pct = len(subset[subset['urban_rural'] == 'urban']) / len(subset) * 100\n",
        "        rural_pct = len(subset[subset['urban_rural'] == 'rural']) / len(subset) * 100\n",
        "        total_area = subset['area_km2'].sum()\n",
        "        \n",
        "        print(f\"   {facility_type}:\")\n",
        "        print(f\"     {len(subset):,} isochrones ({urban_pct:.1f}% urban, {rural_pct:.1f}% rural)\")\n",
        "        print(f\"     Total coverage: {total_area:,.0f} km¬≤\")\n",
        "    \n",
        "    # Coverage efficiency insights\n",
        "    print(f\"\\nüìä Coverage Insights:\")\n",
        "    \n",
        "    # Find which time/facility combinations have highest rural coverage\n",
        "    max_rural_coverage = isochrones_annotated.groupby(['facility_type', 'time_bin']).apply(\n",
        "        lambda x: (x['urban_rural'] == 'rural').sum() / len(x) * 100\n",
        "    ).reset_index()\n",
        "    max_rural_coverage.columns = ['facility_type', 'time_bin', 'rural_pct']\n",
        "    top_rural = max_rural_coverage.nlargest(3, 'rural_pct')\n",
        "    \n",
        "    print(f\"\\nüåæ Highest Rural Coverage Combinations:\")\n",
        "    for _, row in top_rural.iterrows():\n",
        "        print(f\"   {row['facility_type']} - {row['time_bin']} min: {row['rural_pct']:.1f}% rural\")\n",
        "    \n",
        "    # Find largest coverage areas\n",
        "    largest_areas = isochrones_annotated.nlargest(3, 'area_km2')[['facility_name', 'facility_type', 'time_bin', 'area_km2', 'urban_rural']]\n",
        "    print(f\"\\nüìè Largest Coverage Areas:\")\n",
        "    for _, row in largest_areas.iterrows():\n",
        "        facility_name = row['facility_name'][:30] + \"...\" if len(str(row['facility_name'])) > 30 else row['facility_name']\n",
        "        print(f\"   {facility_name} ({row['facility_type']}, {row['time_bin']} min): {row['area_km2']:.0f} km¬≤ ({row['urban_rural']})\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Isochrone analysis complete! Check the exported CSV files for detailed results.\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No isochrone data available for analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isochrone Analysis Summary\n",
        "\n",
        "### ‚úÖ What We've Accomplished\n",
        "\n",
        "This extended analysis now includes **both benefit points AND isochrone coverage areas** for comprehensive urban/rural healthcare accessibility assessment:\n",
        "\n",
        "#### **1. Benefit Point Analysis** \n",
        "- üéØ **Focused analysis** - Areas where CT hospitals provide significant advantages\n",
        "- üìç **Point-based** - Specific locations with calculated time benefits\n",
        "- üèÜ **Decision-focused** - Shows where CT expansion would be most beneficial\n",
        "\n",
        "#### **2. Isochrone Coverage Analysis**\n",
        "- üó∫Ô∏è **Comprehensive coverage** - All areas reachable by each facility within time thresholds  \n",
        "- üîÑ **Time progression** - How accessibility expands from 15‚Üí30‚Üí45‚Üí60 minutes\n",
        "- üìä **Facility comparison** - Direct comparison between stroke units and CT hospitals\n",
        "- üèôÔ∏è **Urban/rural patterns** - Geographic distribution of healthcare accessibility\n",
        "\n",
        "### üìä Export Files Generated\n",
        "\n",
        "#### **Benefit Analysis Exports:**\n",
        "- `benefit_urban_rural_summary.csv` - Benefit categories by urban/rural classification\n",
        "\n",
        "#### **Isochrone Analysis Exports:**\n",
        "- `isochrone_urban_rural_detailed.csv` - Full breakdown by time bin and facility type  \n",
        "- `isochrone_urban_rural_by_facility.csv` - Summary by facility type only\n",
        "- `isochrone_urban_rural_by_time.csv` - Summary by time bin only\n",
        "- `isochrone_urban_rural_area_weighted.csv` - Area-weighted coverage analysis\n",
        "\n",
        "### üéØ Key Applications\n",
        "\n",
        "#### **Policy & Planning:**\n",
        "- **Healthcare equity** - Identify urban vs rural access disparities\n",
        "- **Resource allocation** - Prioritize areas for CT hospital expansion\n",
        "- **Emergency response** - Understand coverage gaps and response times\n",
        "- **Infrastructure planning** - Compare different facility deployment strategies\n",
        "\n",
        "#### **Research Applications:**\n",
        "- **Accessibility modeling** - Quantify healthcare access patterns  \n",
        "- **Geographic analysis** - Spatial patterns of healthcare coverage\n",
        "- **Comparative studies** - Urban vs rural healthcare infrastructure effectiveness\n",
        "- **Time-distance analysis** - Relationship between distance and accessibility\n",
        "\n",
        "### üîç Analysis Insights Pattern\n",
        "\n",
        "Your results will typically show:\n",
        "\n",
        "#### **Benefit Analysis Patterns:**\n",
        "- üåæ **Rural areas** - More likely to benefit significantly from CT hospitals (longer distances to stroke units)\n",
        "- üèôÔ∏è **Urban areas** - More equivalent access (multiple nearby options)\n",
        "- üèúÔ∏è **Healthcare deserts** - Predominantly rural areas with limited access\n",
        "\n",
        "#### **Isochrone Coverage Patterns:**\n",
        "- üìà **Coverage expansion** - Rural areas show larger isochrone growth with time\n",
        "- üèòÔ∏è **Urban efficiency** - Higher facility density leads to overlapping coverage\n",
        "- ‚öñÔ∏è **Access equity** - Rural facilities serve larger geographic areas but fewer people\n",
        "\n",
        "### üöÄ Next Steps\n",
        "\n",
        "This comprehensive analysis provides the foundation for:\n",
        "1. **Detailed mapping** - Create publication-ready maps showing coverage patterns\n",
        "2. **Population analysis** - Weight results by population density for impact assessment  \n",
        "3. **Scenario modeling** - Test different facility placement strategies\n",
        "4. **Policy recommendations** - Evidence-based healthcare infrastructure planning\n",
        "\n",
        "Now you have both the **micro-level** (benefit points) and **macro-level** (coverage areas) perspective on healthcare accessibility across urban and rural Germany!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
